{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the morphometric statistics\n",
    "\n",
    "\n",
    "**Please make sure to preprocess the raw-reconstructions using the preprocess-morph-SWC-files.ipynb before running this notebook**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from neurontree import NeuronTree as nt\n",
    "from neurontree.utils import angle_between\n",
    "import networkx as nx\n",
    "import copy\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "from itertools import combinations,permutations\n",
    "\n",
    "#PLOTTING\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = \"../data/processed/morph/features/\" # <-- add your path here if it differs\n",
    "path_to_reconstructions='../data/processed/morph/nt/' # <-- add your path here if it differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_file_path = \"../data/m1_patchseq_meta_data.csv\"  # <-- add your path here if it differs\n",
    "cells = pd.read_csv(meta_data_file_path, sep='\\t', index_col=0)\n",
    "cells = cells[cells['Traced'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_perc_above_below_overlap(profile_a, profile_b):\n",
    "    \n",
    "    profile_a = np.hstack((np.array([0]),profile_a,np.array([0])))\n",
    "    profile_b = np.hstack((np.array([0]),profile_b,np.array([0])))\n",
    "    a = np.where(profile_a > 0)[0]\n",
    "    b = np.where(profile_b > 0)[0]\n",
    "    \n",
    "    perc_a_above_b = np.sum(profile_a[:b[0]])/np.sum(profile_a)\n",
    "    perc_a_below_b = np.sum(profile_a[b[-1]+1:])/np.sum(profile_a)\n",
    "    perc_a_overlap_b  = 1 - perc_a_above_b - perc_a_below_b\n",
    "    \n",
    "    return (perc_a_above_b,perc_a_below_b,perc_a_overlap_b)\n",
    "\n",
    "def get_longest_neurite(R):\n",
    "    \n",
    "    r = R.get_root()\n",
    "\n",
    "    stem_ids = [s[1] for s in R.edges() if s[0] == r]\n",
    "    \n",
    "    neurite_lengths = dict(zip(stem_ids,[0]*len(stem_ids)))\n",
    "    neurite_paths = dict()\n",
    "    G = R.get_graph()\n",
    "    \n",
    "    # get the path length and the path of each neurite extending from the soma\n",
    "    for t in R.get_tips():\n",
    "        path_length = nx.dijkstra_path_length(G,r,t,weight='path_length')\n",
    "        path = nx.dijkstra_path(G,r,t)\n",
    "\n",
    "        stem_ix = path[1]\n",
    "        neurite_lengths[stem_ix] += path_length \n",
    "        if stem_ix in neurite_paths.keys():\n",
    "            neurite_paths[stem_ix] += path\n",
    "        else:\n",
    "            neurite_paths[stem_ix] = path\n",
    "            \n",
    "    keys = list(neurite_lengths.keys())\n",
    "    values = list(neurite_lengths.values())\n",
    "    argix = np.argmax(values)\n",
    "    \n",
    "    #get subgraph with all nodes\n",
    "    subgraph = nx.subgraph(G,set(neurite_paths[keys[argix]]))\n",
    "    \n",
    "    return nt.NeuronTree(graph=subgraph)\n",
    "\n",
    "\n",
    "def get_morphometrics(T, item):\n",
    "\n",
    "    \n",
    "    z = dict()\n",
    "    depth = item['Soma depth (µm)']\n",
    "    thickness = item['Cortical thickness (µm)']\n",
    "    z['normalized depth'] = depth/thickness\n",
    "   \n",
    "    for part in ['axon', 'dendrite']:\n",
    "\n",
    "        if part == 'axon':\n",
    "            T = N.get_axonal_tree()\n",
    "        elif part == 'dendrite':\n",
    "            T = N.get_dendritic_tree() \n",
    "\n",
    "\n",
    "        if len(T.nodes()) > 5:\n",
    "\n",
    "            z[part+ ' branch points'] = T.get_branchpoints().size\n",
    "            extend = T.get_extend()\n",
    "\n",
    "            z[part + ' width'] = extend[0]\n",
    "            z[part + ' depth'] = extend[1]\n",
    "            z[part + ' height'] = extend[2]\n",
    "\n",
    "            robust_extend = T.get_extend(robust=True)\n",
    "            z[part + ' robust width'] = robust_extend[0]\n",
    "            z[part + ' robust depth'] = robust_extend[1]\n",
    "            z[part + ' robust height'] = robust_extend[2]\n",
    "\n",
    "            pos = np.array(list(T.get_node_attributes('pos').values()))\n",
    "            bias = np.max(pos,axis=0) + np.min(pos, axis=0)\n",
    "\n",
    "            z[part + ' x-bias'] = np.abs(bias[0])\n",
    "            z[part + ' z-bias'] = bias[2]\n",
    "\n",
    "            z[part + ' tips'] = T.get_tips().size\n",
    "\n",
    "            z[part + ' total length'] = np.sum(list(T.get_edge_attributes('euclidean_dist').values()))\n",
    "\n",
    "            z[part + ' max path distance to soma'] = np.max(list(T.get_path_length().values()))\n",
    "            z[part + ' max branch order'] = np.max(list(T.get_branch_order().values()))\n",
    "\n",
    "            path_angles = []\n",
    "            for p1 in T.get_path_angles().items():\n",
    "                if p1:\n",
    "                    path_angles += [p1[1]]\n",
    "\n",
    "            z[part + ' max path angle'] = np.percentile(path_angles,99.5)\n",
    "            z[part + ' median path angle'] = np.median(path_angles)\n",
    "\n",
    "            R = T.get_topological_minor()\n",
    "            \n",
    "            # maximal segment path length\n",
    "            z[part + ' max segment length'] = np.max(list(R.get_segment_length().values()))\n",
    "\n",
    "            tortuosity = [e[2]['path_length'] / e[2]['euclidean_dist'] for e in R.edges(data=True)]\n",
    "\n",
    "            z[part + ' log max tortuosity'] = np.log(np.percentile(tortuosity,99.5))\n",
    "            z[part + ' log min tortuosity'] = np.log(np.min(tortuosity))\n",
    "            z[part + ' log median tortuosity'] = np.log(np.median(tortuosity))\n",
    "\n",
    "            branch_angles = list(R.get_branch_angles().values())\n",
    "            if branch_angles:\n",
    "                z[part + ' max branch angle'] = np.max(branch_angles)\n",
    "                z[part + ' min branch angle'] = np.min(branch_angles)\n",
    "                z[part + ' mean branch angle'] = np.mean(branch_angles)\n",
    "            else:\n",
    "                z[part + ' max branch angle'] = np.nan\n",
    "                z[part + ' min branch angle'] = np.nan\n",
    "                z[part + ' mean branch angle'] = np.nan\n",
    "\n",
    "\n",
    "            # z-profiles\n",
    "            resampled_nodes = T.resample_nodes(d=1)\n",
    "            z_profile, _ = np.histogram(-1*((resampled_nodes[:,2] - depth)/thickness), \n",
    "                                            bins=20, range=[0,1], density=True)\n",
    "            soma_centered_z_profile, _ = np.histogram(((resampled_nodes[:,2])/thickness),\n",
    "                                                      bins=81, range=[-1,1], density=True)\n",
    "            \n",
    "            z[part + ' z-profile'] = z_profile\n",
    "            z[part + ' soma-centered z-profile'] = [soma_centered_z_profile]\n",
    "\n",
    "            z[part + ' above soma'] = np.sum(resampled_nodes[:,2]>0)/resampled_nodes[:,2].shape[0]\n",
    "\n",
    "            radii = R.get_node_attributes('radius')\n",
    "            edges = R.edges()\n",
    "            r = R.get_root()\n",
    "\n",
    "            z['soma radius'] = radii[int(r)]\n",
    "\n",
    "            if part == 'axon':\n",
    "\n",
    "                # get thickness of initial segments\n",
    "                node_ids = [e[1] for e in edges if (e[0] == r)]\n",
    "                initial_segments_radius = [radii[int(n)] for n in node_ids]\n",
    "                z['mean initial segment radius'] = np.mean(initial_segments_radius)\n",
    "\n",
    "            # get mean neurite thickness\n",
    "            radii.pop(r)  # remove the soma as it is usually the thickest\n",
    "            z[part + ' mean neurite radius'] = np.mean(list(radii.values()))\n",
    "\n",
    "        \n",
    "            ec = []\n",
    "            G = R.get_graph()\n",
    "            for p in np.concatenate((R.get_tips(),R.get_branchpoints())):\n",
    "                ec.append(np.sqrt(np.sum(G.node[p]['pos']**2)))\n",
    "\n",
    "            z[part + ' max Euclidean dist'] = np.max(ec)\n",
    "\n",
    "\n",
    "            # get bifurcation moments\n",
    "            branch_point_positions = [R.get_graph().node[k]['pos'] for k in R.get_branchpoints()]\n",
    "            if branch_point_positions:\n",
    "                z[part + ' first bifurcation moment'] = np.mean(branch_point_positions, axis=0)[2]\n",
    "                z[part + ' bifurcation standard deviation'] = np.std(branch_point_positions, axis=0)[2]\n",
    "\n",
    "\n",
    "            if part == 'dendrite':\n",
    "\n",
    "                stems = [R.get_graph().node[k[1]]['pos'] for k in R.edges(R.get_root())]\n",
    "                # only calculated in xz plane in degree\n",
    "                stem_exit_angles = np.array([angle_between([0,-1],s[[0,2]])/np.pi*180 for s in stems])\n",
    "\n",
    "                # stems\n",
    "                z['stems'] = len(stems)\n",
    "\n",
    "                # stem exit histogram\n",
    "                z['stems exiting up'] = np.sum(stem_exit_angles < 45 )/len(stems)\n",
    "                z['stems exiting down'] = np.sum(stem_exit_angles > 135 )/len(stems)\n",
    "                z['stems exiting to the sides']= np.sum((stem_exit_angles>=45) & (stem_exit_angles <= 135))/len(stems)\n",
    "\n",
    "                # now get morphometrics for longest dendrite\n",
    "                L = get_longest_neurite(R)\n",
    "                \n",
    "                # get branch point positions for apical\n",
    "                bpp_L = [L.get_graph().node[k]['pos'] for k in L.get_branchpoints()]\n",
    "                \n",
    "                path_length = nx.single_source_dijkstra_path_length(L.get_graph(), source=L.get_root(),weight='path_length')\n",
    "                # get furthes node and the line to it from soma. Furthest in terms of path length.\n",
    "\n",
    "                G = L.get_graph()\n",
    "                tips = L.get_tips()\n",
    "                pl = [path_length[t] for t in tips]\n",
    "                \n",
    "\n",
    "                farthest_tip = tips[np.argmax(pl)]\n",
    "                farthest_tip_pos = G.node[farthest_tip]['pos']\n",
    "                max_pl = np.max(pl)\n",
    "\n",
    "                proj_bp = [np.dot(bpp,farthest_tip_pos)/np.linalg.norm(farthest_tip_pos)/max_pl\n",
    "                           for bpp in bpp_L]\n",
    "\n",
    "                if proj_bp:\n",
    "                    # mean bifurcation distance\n",
    "                    z['\"apical\" mean bifurcation distance'] = np.mean(proj_bp)\n",
    "\n",
    "                    # std bifurcation distance\n",
    "                    z['\"apical\" std bifurcation distance'] = np.std(proj_bp)\n",
    "\n",
    "    \n",
    "                # number of outer bifurcations\n",
    "                ec = []\n",
    "                for t in tips:\n",
    "                    ec.append(np.sqrt(np.sum(G.node[t]['pos']**2)))\n",
    "\n",
    "                max_ec = np.max(ec)\n",
    "\n",
    "                outer_bifurcations = 0\n",
    "                for bp in L.get_branchpoints():\n",
    "                    if np.sqrt(np.sum(G.node[bp]['pos']**2)) > max_ec/2:\n",
    "                        outer_bifurcations += 1\n",
    "                        \n",
    "                z['\"apical\" log1p number of outer bifurcations'] = np.log(outer_bifurcations + 1) \n",
    "                \n",
    "                z['\"apical\" height'] = L.get_extend()[2]\n",
    "                z['\"apical\" width'] = L.get_extend()[0]\n",
    "                \n",
    "                z['\"apical\" robust height'] = L.get_extend(robust=True)[2]\n",
    "                z['\"apical\" robust width'] = L.get_extend(robust=True)[0]\n",
    "                \n",
    "                z['\"apical\" total length'] = np.sum(list(L.get_edge_attributes('path_length').values()))\n",
    "                z['\"apical\" branch points'] = len(L.get_branchpoints())\n",
    "        else:\n",
    "            print(\"No %s recovered\"%part)\n",
    "\n",
    "        # get the overlap and earth mover's distance here\n",
    "        # overlap\n",
    "        for key1, key2 in permutations(['axon z-profile', 'dendrite z-profile'],2):\n",
    "            try:\n",
    "                profile_a = z[key1]\n",
    "                profile_b = z[key2]\n",
    "\n",
    "                above, below, overlap = get_perc_above_below_overlap(profile_a,profile_b)\n",
    "                z['Log1p fraction of %s above %s'%(key1.split(\" \")[0], key2.split(\" \")[0])]= np.log(1+above)\n",
    "                z['Log1p fraction of %s below %s'%(key1.split(\" \")[0], key2.split(\" \")[0])]= np.log(1+below)\n",
    "               \n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "\n",
    "        # earth mover's distance\n",
    "        for key1, key2 in combinations(['axon z-profile', 'dendrite z-profile'],2):\n",
    "            try:\n",
    "                profile_a = z[key1]\n",
    "                profile_b = z[key2]\n",
    "\n",
    "                z['EMD %s %s'%(key1.split(\" \")[0], key2.split(\" \")[0])] = wasserstein_distance(profile_a,profile_b)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "\n",
    "    # make the arrays a list\n",
    "    for key in ['axon z-profile', 'dendrite z-profile']:\n",
    "        try:\n",
    "            z[key] = [z[key]]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for rn, item in list(cells.iterrows()):\n",
    "\n",
    "    file_name = item['Cell']\n",
    "            \n",
    "    if not os.path.exists(save_path + file_name + '.csv'):\n",
    "        \n",
    "        print('%i: Calculating morphometric statistics for %s' % (rn,file_name))\n",
    "        \n",
    "        \n",
    "        # load in data\n",
    "        swc = pd.read_csv(path_to_reconstructions + file_name +\".swc\", \n",
    "                          delim_whitespace=True, comment='#',\n",
    "                              names=['n', 'type', 'x', 'y', 'z', 'radius', 'parent'], index_col=False)\n",
    "        # create a neurontree\n",
    "        N = nt.NeuronTree(swc=swc)\n",
    "\n",
    "        z = dict()\n",
    "        z['cell id'] = file_name\n",
    "        \n",
    "        # get the morphometrics\n",
    "        d = get_morphometrics(N, item)\n",
    "        \n",
    "        z.update(d)\n",
    "        \n",
    "        # save data \n",
    "        morphometry_data = pd.DataFrame(z)\n",
    "        morphometry_data.to_csv(save_path+ file_name + \".csv\")        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore morphometric features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = save_path\n",
    "\n",
    "# load in all morphometrics files into one data frame\n",
    "morphometrics = pd.DataFrame()\n",
    "root, _, files = list(os.walk(data_path))[0]\n",
    "for f in files:\n",
    "    temp = pd.read_csv(data_path+f, index_col=0)\n",
    "    morphometrics = morphometrics.append(temp)\n",
    "\n",
    "morphometrics = morphometrics.reset_index()\n",
    "del morphometrics['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_idx = list(morphometrics.columns)\n",
    "full_idx.remove('cell id')\n",
    "full_idx.remove('dendrite z-profile')\n",
    "full_idx.remove('axon z-profile')\n",
    "full_idx.remove('axon soma-centered z-profile')\n",
    "full_idx.remove('dendrite soma-centered z-profile')\n",
    "len(full_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create indices for excitatory and inhibitory cells\n",
    "excitatory_index = (cells['RNA family'] == 'CT') | (cells['RNA family'] == 'IT') | \\\n",
    "                    (cells['RNA family'] == 'ET') |(cells['RNA family'] == 'NP') | (cells['RNA family'] == 'PT') |\\\n",
    "                    (cells['Cell'] == '20180115_sample_6' ) | (cells['Cell'] == '20180208_sample_1' ) |\\\n",
    "                    (cells['Cell'] == '20180315_sample_2' ) | (cells['Cell'] == '20180509_sample_1' ) | \\\n",
    "                    (cells['Cell'] == '20180828_sample_7' ) | (cells['Cell'] == '20190722_sample_7' )\n",
    "\n",
    "\n",
    "\n",
    "inhibitory_index = (cells['RNA family'] == 'Lamp5') | (cells['RNA family'] == 'Pvalb') | \\\n",
    "                    (cells['RNA family'] == 'Sncg') | (cells['RNA family'] == 'Sst') | \\\n",
    "                    (cells['RNA family'] == 'Vip') | (cells['Cell'] == '20190606_sample_7') | \\\n",
    "                    (cells['Cell'] == '20190905_sample_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excitatory cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only pyramidal cells\n",
    "pyramidal_cells = morphometrics.set_index('cell id').loc[cells[excitatory_index]['Cell'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting Log1p fraction of dendrite below axon\n",
      "deleting axon depth\n",
      "deleting dendrite depth\n",
      "deleting Log1p fraction of dendrite above axon\n",
      "deleting axon total length\n",
      "deleting axon max branch angle\n",
      "deleting axon tips\n",
      "deleting axon mean neurite radius\n",
      "deleting mean initial segment radius\n",
      "deleting axon log min tortuosity\n",
      "deleting axon log median tortuosity\n",
      "deleting axon log max tortuosity\n",
      "deleting axon robust height\n",
      "deleting Log1p fraction of axon below dendrite\n",
      "deleting axon max branch order\n",
      "deleting axon branch points\n",
      "deleting axon mean branch angle\n",
      "deleting axon robust depth\n",
      "deleting axon max path distance to soma\n",
      "deleting EMD axon dendrite\n",
      "deleting axon median path angle\n",
      "deleting axon x-bias\n",
      "deleting axon max path angle\n",
      "deleting axon first bifurcation moment\n",
      "deleting axon bifurcation standard deviation\n",
      "deleting Log1p fraction of axon above dendrite\n",
      "deleting axon height\n",
      "deleting axon width\n",
      "deleting axon max segment length\n",
      "deleting axon z-bias\n",
      "deleting axon robust width\n",
      "deleting axon above soma\n",
      "deleting axon min branch angle\n",
      "deleting dendrite robust depth\n",
      "deleting axon max Euclidean dist\n"
     ]
    }
   ],
   "source": [
    "idx_exc_morphometrics = copy.copy(full_idx)\n",
    "\n",
    "# remove features that are not computed for more than 100 cells in the dataset\n",
    "indices, counts = np.unique(np.where(pyramidal_cells[full_idx].isnull())[1], return_counts=True)\n",
    "to_remove = [idx_exc_morphometrics[z] for z in indices[counts>100]]\n",
    "\n",
    "# remove depth features because of the flattening of biocytin stainings in this direction\n",
    "to_remove +=['axon robust height', 'axon robust width', 'axon robust depth',\n",
    "             'dendrite depth', 'dendrite robust depth']\n",
    "for z in set(to_remove):\n",
    "    print('deleting %s'%z)\n",
    "    idx_exc_morphometrics.remove(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramidal_cells = pyramidal_cells[idx_exc_morphometrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coefficient of variation \n",
    "\n",
    "$c_v = \\frac{\\sigma}{\\mu}$ \n",
    "\n",
    "Exclude everything that has $c_v < .25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dendrite above soma', 'dendrite log median tortuosity',\n",
       "       'dendrite max branch angle', 'dendrite max path angle',\n",
       "       'dendrite mean branch angle'], dtype='<U43')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# morphometrics to be excluded due to little variation\n",
    "cv_threshold = .25\n",
    "np.array(idx_exc_morphometrics)[(pyramidal_cells.abs().std()/pyramidal_cells.abs().mean() < cv_threshold).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining features:  ['\"apical\" branch points' '\"apical\" height'\n",
      " '\"apical\" log1p number of outer bifurcations'\n",
      " '\"apical\" mean bifurcation distance' '\"apical\" robust height'\n",
      " '\"apical\" robust width' '\"apical\" std bifurcation distance'\n",
      " '\"apical\" total length' '\"apical\" width'\n",
      " 'dendrite bifurcation standard deviation' 'dendrite branch points'\n",
      " 'dendrite first bifurcation moment' 'dendrite height'\n",
      " 'dendrite log max tortuosity' 'dendrite log min tortuosity'\n",
      " 'dendrite max Euclidean dist' 'dendrite max branch order'\n",
      " 'dendrite max path distance to soma' 'dendrite max segment length'\n",
      " 'dendrite mean neurite radius' 'dendrite median path angle'\n",
      " 'dendrite min branch angle' 'dendrite robust height'\n",
      " 'dendrite robust width' 'dendrite tips' 'dendrite total length'\n",
      " 'dendrite width' 'dendrite x-bias' 'dendrite z-bias' 'normalized depth'\n",
      " 'soma radius' 'stems' 'stems exiting down' 'stems exiting to the sides'\n",
      " 'stems exiting up']  \n",
      " number of features:  35\n"
     ]
    }
   ],
   "source": [
    "idx_after_cv = np.array(idx_exc_morphometrics)[(pyramidal_cells.abs().std()/pyramidal_cells.abs().mean() >= cv_threshold).values]\n",
    "print('remaining features: ', idx_after_cv, ' \\n number of features: ', len(idx_after_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of excitatory features:  35\n"
     ]
    }
   ],
   "source": [
    "final_exc_idx = idx_after_cv\n",
    "print('Final number of excitatory features: ', len(final_exc_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhibitory cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only inhibitory cells\n",
    "inhibitory_cells = morphometrics.set_index('cell id').loc[cells[inhibitory_index]['Cell'].values]\n",
    "len(full_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting \"apical\" log1p number of outer bifurcations\n",
      "deleting axon depth\n",
      "deleting dendrite depth\n",
      "deleting \"apical\" std bifurcation distance\n",
      "deleting axon robust depth\n",
      "deleting \"apical\" mean bifurcation distance\n",
      "deleting dendrite robust depth\n",
      "deleting \"apical\" branch points\n",
      "deleting \"apical\" robust height\n",
      "deleting \"apical\" height\n",
      "deleting \"apical\" width\n",
      "deleting \"apical\" robust width\n",
      "deleting \"apical\" total length\n"
     ]
    }
   ],
   "source": [
    "idx_inh_morphometrics = copy.copy(full_idx)\n",
    "indices, counts = np.unique(np.where(inhibitory_cells[full_idx].isnull())[1], return_counts=True)\n",
    "\n",
    "to_remove = [idx_inh_morphometrics[z] for z in indices[counts> 100]]\n",
    "to_remove += [k for k in morphometrics.columns if k.find('\"apical\"')>-1 ]\n",
    "to_remove += ['axon depth', 'axon robust depth', 'dendrite depth', 'dendrite robust depth']\n",
    "for z in set(to_remove):\n",
    "    print('deleting %s'%z)\n",
    "    idx_inh_morphometrics.remove(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features excluded due to little variation: \n",
      " ['axon log max tortuosity' 'axon log median tortuosity'\n",
      " 'axon max branch angle' 'axon max path angle' 'axon mean branch angle'\n",
      " 'axon median path angle' 'dendrite max path angle'\n",
      " 'dendrite mean branch angle' 'dendrite median path angle']\n",
      "remaining features: \n",
      " ['EMD axon dendrite' 'Log1p fraction of axon above dendrite'\n",
      " 'Log1p fraction of axon below dendrite'\n",
      " 'Log1p fraction of dendrite above axon'\n",
      " 'Log1p fraction of dendrite below axon' 'axon above soma'\n",
      " 'axon bifurcation standard deviation' 'axon branch points'\n",
      " 'axon first bifurcation moment' 'axon height' 'axon log min tortuosity'\n",
      " 'axon max Euclidean dist' 'axon max branch order'\n",
      " 'axon max path distance to soma' 'axon max segment length'\n",
      " 'axon mean neurite radius' 'axon min branch angle' 'axon robust height'\n",
      " 'axon robust width' 'axon tips' 'axon total length' 'axon width'\n",
      " 'axon x-bias' 'axon z-bias' 'dendrite above soma'\n",
      " 'dendrite bifurcation standard deviation' 'dendrite branch points'\n",
      " 'dendrite first bifurcation moment' 'dendrite height'\n",
      " 'dendrite log max tortuosity' 'dendrite log median tortuosity'\n",
      " 'dendrite log min tortuosity' 'dendrite max Euclidean dist'\n",
      " 'dendrite max branch angle' 'dendrite max branch order'\n",
      " 'dendrite max path distance to soma' 'dendrite max segment length'\n",
      " 'dendrite mean neurite radius' 'dendrite min branch angle'\n",
      " 'dendrite robust height' 'dendrite robust width' 'dendrite tips'\n",
      " 'dendrite total length' 'dendrite width' 'dendrite x-bias'\n",
      " 'dendrite z-bias' 'mean initial segment radius' 'normalized depth'\n",
      " 'soma radius' 'stems' 'stems exiting down' 'stems exiting to the sides'\n",
      " 'stems exiting up']  \n",
      " number of features:  53\n"
     ]
    }
   ],
   "source": [
    "inhibitory_cells = inhibitory_cells[idx_inh_morphometrics]\n",
    "\n",
    "# morphometrics to be excluded due to little variation\n",
    "print('Features excluded due to little variation: \\n', np.array(idx_inh_morphometrics)[(inhibitory_cells.abs().std()/inhibitory_cells.abs().mean() < 0.25).values])\n",
    "\n",
    "idx_after_cv = np.array(idx_inh_morphometrics)[(inhibitory_cells.abs().std()/inhibitory_cells.abs().mean() >= 0.25).values]\n",
    "print('remaining features: \\n', idx_after_cv, ' \\n number of features: ', len(idx_after_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of inhibitory features:  50\n"
     ]
    }
   ],
   "source": [
    "final_inh_idx = list(idx_after_cv)\n",
    "\n",
    "# exclude features after visual inspection\n",
    "to_remove = [ 'Log1p fraction of dendrite below axon',\n",
    "             'dendrite max branch angle', 'dendrite min branch angle']\n",
    "\n",
    "for z in to_remove:\n",
    "    final_inh_idx.remove(z)\n",
    "\n",
    "print('Final number of inhibitory features: ', len(final_inh_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate and store the features\n",
    "\n",
    "## Morphometric statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "e_morph = pyramidal_cells[final_exc_idx]\n",
    "e_morph.loc[:,'cell class'] = 'exc'\n",
    "\n",
    "i_morph = inhibitory_cells[final_inh_idx]\n",
    "i_morph.loc[:,'cell class'] = 'inh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphometric_used = pd.concat((e_morph,i_morph))\n",
    "morphometric_used.to_csv('../data/m1_patchseq_morph_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "excitatory_cells = morphometrics.set_index('cell id').loc[cells[excitatory_index]['Cell'].values]\n",
    "\n",
    "\n",
    "profile_dict_e= dict()\n",
    "for rn,item in list(excitatory_cells.iterrows()):\n",
    "    profile = item['dendrite z-profile']\n",
    "    if profile:\n",
    "        s = profile.replace('\\n', '').replace('[', '').replace(']','')\n",
    "        no = [x for x in s.split(' ') if x != '']\n",
    "        profile_dict_e[rn] = np.array([float(n) for n in no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitory_cells = morphometrics.set_index('cell id').loc[cells[inhibitory_index]['Cell'].values]\n",
    "    \n",
    "# first load them assigned to their index/name. Then put them in an array. To make sure they correspond. \n",
    "profile_dict_i=dict()\n",
    "for rn,item in list(inhibitory_cells.iterrows()):\n",
    "    profile_dict_i[rn] = np.array([])\n",
    "    for profile in item[['axon z-profile']]:\n",
    "        if profile is not np.nan:\n",
    "            s = profile.replace('\\n', '').replace('[', '').replace(']','')\n",
    "            no = [x for x in s.split(' ') if x != '']\n",
    "            temp = np.array([float(n) for n in no])\n",
    "        else:\n",
    "            temp = np.zeros((1,20))\n",
    "        \n",
    "        if profile_dict_i[rn].size == 0:\n",
    "            profile_dict_i[rn] = temp\n",
    "        else:  \n",
    "            profile_dict_i[rn] = np.vstack((profile_dict_i[rn],temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_profiles = (pd.DataFrame(profile_dict_e).T).append(pd.DataFrame(profile_dict_i).T)\n",
    "z_profiles = z_profiles.reset_index().rename(columns={'index':'cell id'}).set_index('cell id')\n",
    "z_profiles.to_csv(\"../data/m1_patchseq_morph_zprofiles.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
